<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="Deformable Neural Radiance Fields creates free-viewpoint portraits (nerfies) from casually captured videos.">
  <meta name="keywords" content="Nerfies, D-NeRF, NeRF">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>ECIR 2024 Tutorial: Recent Advances in Generative Information Retrieval</title>


  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.svg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>

<nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
</nav>


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-2 publication-title">
              <span style="font-size: 80%">ECIR 2024 Tutorial:</span><br />
              Recent Advances in Generative Information Retrieval
            </h1>

          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <table>
            <tr>
                <!-- <th scope="row">TR-7</th> -->
                <td width="20%" style="text-align: center; padding: 10px"><img width="150px" height="150px" src="static/imgs/profile_tangyubao.jpg"></td>
                <td width="20%" style="text-align: center; padding: 10px"><img width="150px" height="150px" src="static/imgs/profile_ruqing.jpg"></td>
                <td width="20%" style="text-align: center; padding: 10px"><img width="150px" height="150px" src="static/imgs/profile_zhaochunren.png"></td>
                <td width="20%" style="text-align: center; padding: 10px"><img width="150px" height="150px" src="static/imgs/profile_jiafeng.jpg"></td>
                <td width="20%" style="text-align: center; padding: 10px"><img width="150px" height="150px" src="static/imgs/profile_mdr.jpg"></td>
            </tr>
              <tr>
                <!-- <th scope="row">TR-7</th> -->
                <td width="20%" style="text-align: center"><a href="https://github.com/lightningtyb" style="border-radius: 50%">Yubao Tang</a><sup>1</sup>,</td>
                <td width="20%" style="text-align: center"><a href="https://daqingchong.github.io/" style="border-radius: 50%">Ruqing Zhang</a><sup>1</sup>,</td>
                <td width="20%" style="text-align: center"><a href="https://renzhaochun.github.io/" style="border-radius: 50%">Zhaochun Ren</a><sup>2</sup>,</td>
                <td width="20%" style="text-align: center"><a href="http://www.bigdatalab.ac.cn/gjf/" style="border-radius: 50%">Jiafeng Guo</a><sup>1</sup>,</td>
                <td width="20%" style="text-align: center"><a href="https://staff.fnwi.uva.nl/m.derijke/" style="border-radius: 50%">Maarten de Rijke</a><sup>3</sup></td>
              </tr>
            </table>
            </span>
          </div>
          <div class="is-size-6 publication-authors">
            <span class="author-block"><sup>1</sup>CAS Key Lab of Network Data Science and Technology, ICT, CAS, University of Chinese Academy of Sciences, </span>
            <span class="author-block"><sup>2</sup>Leiden University</span>
            <span class="author-block"><sup>3</sup>University of Amsterdam</span>

          </div>
          <br />
          <div class="is-size-5 publication-authors">
            <b>Thursday 28th March 2024</b>
          </div>
          <!-- <div class="is-size-5 publication-authors">
            Zoom link available on <a href="https://underline.io/events/395/sessions?eventSessionId=15330&searchGroup=lecture" target="_blank">Underline</a>
          </div> -->
        </div>
      </div>
    </div>
  </div>
</section>
<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">About this tutorial</h2>
        <div class="content has-text-justified">
          <p>
            Generative retrieval (GR) has become a highly active area of information retrieval (IR) that has witnessed significant growth recently.
            Compared to the traditional ``index-retrieve-then-rank'' pipeline, the GR paradigm aims to consolidate all information within a corpus into a single model.
            Typically, a sequence-to-sequence model is trained to directly map a query to its relevant document identifiers (i.e., docids).
            This tutorial offers an introduction to the core concepts of the GR paradigm and a comprehensive overview of recent advances in its foundations and applications.
          </p>
          <p>
            We start by providing preliminary information covering foundational aspects and problem formulations of GR.
            Then, our focus shifts towards recent progress in docid design, training approaches, inference strategies, and the applications of GR.
            We end by outlining remaining challenges and issuing a call for future GR research.
            This tutorial is intended to be beneficial to both researchers and industry practitioners interested in developing novel GR solutions or applying them in real-world scenarios.
          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->

    <!-- Paper video. -->
    <!--/ Paper video. -->
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">

    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Schedule</h2>
        <p>
          Our tutorial is scheduled for Thursday 28th March 2024.
          <em>Please note that there could be revisions to the presentation slides.</em> 
          <a href="./slides/GR_Tutorial_Slides-20231128.pdf" target='_blank'>[Slides]</a>
        </p>

        <div class="content has-text-justified">

          <style type="text/css">
          .tg  {border-collapse:collapse;border-spacing:0;}
          .tg td{border-color:black;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;
            overflow:hidden;padding:10px 5px;word-break:normal;}
          .tg th{border-color:black;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;
            font-weight:normal;overflow:hidden;padding:10px 5px;word-break:normal;}
          .tg .tg-0pky{border-color:inherit;text-align:left;vertical-align:top}
          .tg .tg-0lax{text-align:left;vertical-align:top}
          </style>
          <table class="tg">
          <thead>
            <tr>
              <th class="tg-0pky">Time</th>
              <th class="tg-0lax">Section</th>
              <th class="tg-0lax">Presenter</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td class="tg-0lax">13:00 — 13:10</td>
              <td class="tg-0lax">Section 1: Introduction</td>
              <td class="tg-0lax">Maarten de Rijke</td>
            </tr>
            <tr>
              <td class="tg-0lax">13:10 — 13:30</td>
              <td class="tg-0lax">Section 2: Definition & Preliminaries</td>
              <td class="tg-0lax">Jiafeng Guo</td>
            </tr>
            <tr>
              <td class="tg-0lax">13:30 — 14:30</td>
              <td class="tg-0lax">Section 3: Docid designs</td>
              <td class="tg-0lax">Yubao Tang</td>
            </tr>
            <tr>
              <td class="tg-0lax">14:30 — 14:45</td>
              <td class="tg-0lax">15min coffee break</td>
              <td class="tg-0lax"></td>
            </tr>
            <tr>
              <td class="tg-0lax">14:45 — 15:20</td>
              <td class="tg-0lax">Section 4: Training approaches</td>
              <td class="tg-0lax">Ruqing Zhang</td>
            </tr>
            <tr>
              <td class="tg-0lax">15:20 — 15:40</td>
              <td class="tg-0lax">Section 5: Inference strategies</td>
              <td class="tg-0lax">Ruqing Zhang</td>
            </tr>
            <tr>
              <td class="tg-0lax">15:40 — 16:00</td>
              <td class="tg-0lax">Section 6: Applications</td>
              <td class="tg-0lax">Yubao Tang</td>
            </tr>
            <tr>
              <td class="tg-0lax">16:00 — 16:10</td>
              <td class="tg-0lax">Section 7: Challenges & Opportunities</td>
              <td class="tg-0lax">Maarten de Rijke</td>
            </tr>
            <tr>
              <td class="tg-0lax">16:10 — 16:30</td>
              <td class="tg-0lax">Q & A</td>
              <td class="tg-0lax">All</td>
            </tr>
          </tbody>
          </table>
        </div>
      </div>
    </div>

    <!-- Concurrent Work. -->
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Reading List</h2>

        <p>The tutorial extensively covers papers highlighted in <b>bold</b>.</p>

        <br />        
        <h3 class="title is-5">Section 3: Docid design</h3>
        <h4 class="title is-5">3.1 Pre-defined docids</h4>

        <h5 class="title is-5">3.1.1 A single docid represents a document</h5>

        <h6 class="title is-5">3.1.1.1 Number-based docids</h6>
        <p><b>Unstructured atomic integers</b></pp>
        <ul>
          <li><a href="https://arxiv.org/pdf/2202.06991.pdf"><b>Transformer Memory as a Differentiable Search Index</b></a> (Tay et al. 2022)</li>
          <li><a href="https://arxiv.org/pdf/2203.00537.pdf">DynamicRetriever: A Pre-trained Model-based IR System Without an Explicit Index</a> (Zhou et al. 2023)</li>
          <li><a href="https://arxiv.org/pdf/2306.11397.pdf">Generative Retrieval as Dense Retrieval</a> (Nguyen and Yates et al. 2023c)</li>
          <li><a href="https://arxiv.org/pdf/2208.09257.pdf">Ultron: An ultimate retriever on corpus with a model-based indexer</a> (Zhou et al. 2022)</li>
          <li><a href="https://arxiv.org/pdf/2210.00328.pdf">CodeDSI: Differentiable Code Search</a> (Nadeem et al. 2022)</li>
          <li><a href="https://arxiv.org/pdf/2212.09744.pdf">DSI++: Updating Transformer Memory with New Documents</a> (Mehta et al. 2022)</li>
        </ul>

        <br />
        <p><b>Naively structured strings</b></pp>

          <ul>
            <li><a href="https://arxiv.org/pdf/2202.06991.pdf"><b>Transformer Memory as a Differentiable Search Index</b></a> (Tay et al. 2022)</li>
            <li><a href="https://arxiv.org/pdf/2206.10128.pdf">Bridging the Gap between Indexing and Retrieval for Differentiable Search Index with Query Generation</a> (Zhuang et al. 2023)</li>
            <li><a href="https://arxiv.org/pdf/2210.00328.pdf">CodeDSI: Differentiable Code Search</a> (Nadeem et al. 2022)</li>
         </ul>
         <br />
         <p><b>Semantically structured strings</b></pp>
          <ul>
            <li><a href="https://arxiv.org/pdf/2202.06991.pdf"><b>Transformer Memory as a Differentiable Search Index</b></a> (Tay et al. 2022)</li>
            <li><a href="https://arxiv.org/pdf/2206.02743.pdf">A Neural Corpus Indexer for Document Retrieval</a> (Wang et al. 2022)</li>
            <li><a href="https://arxiv.org/pdf/2305.02073.pdf">Understanding Differential Search Index for Text Retrieval</a> (Chen et al. 2023c)            </li>
            <li><a href="https://arxiv.org/pdf/2210.00328.pdf">CodeDSI: Differentiable Code Search</a> (Nadeem et al. 2022)</li>
          </ul>
          <br />
          <p><b> Product quantization strings</b></pp>
            <ul>
              <li><a href="https://arxiv.org/pdf/2208.09257.pdf"><b>Ultron: An ultimate retriever on corpus with a model-based indexer</b></a> (Zhou et al. 2022)</li>
              <li><a href="https://arxiv.org/pdf/2308.14968.pdf">Continual Learning for Generative Retrieval over Dynamic Corpora</a> (Chen et al. 2023a)</li>
              <li><a href="https://arxiv.org/pdf/2305.05065.pdf">Recommender Systems with Generative Retrieval</a> (Rajput et al. 2023)</li>
            </ul>

        <br />
        <h6 class="title is-5">3.1.1.2 Word-based docids</h6>
        <p><b> Titles</b></pp>
          <ul>
            <li><a href="https://arxiv.org/pdf/2010.00904"><b>Autoregressive Entity Retrieval</b></a> (De Cao et al. 2021) </li>
            <li><a href="https://arxiv.org/pdf/2208.07652">CorpusBrain: Pre-train a Generative Retrieval Model for Knowledge-Intensive Language Tasks</a> (Chen et al. 2022b)</li>
            <li><a href="https://arxiv.org/pdf/2204.05511">GERE: Generative evidence retrieval for fact verification</a> (Chen et al. 2022a)</li>
            <li><a href="https://arxiv.org/pdf/2211.09388">Data-efficient Autoregressive Document Retrieval for Fact Verification</a> (Thorne et al. 2022)</li>
            <li><a href="https://arxiv.org/pdf/2208.09257.pdf">Ultron: An ultimate retriever on corpus with a model-based indexer</a> (Zhou et al. 2022)</li>
            <li><a href="https://arxiv.org/pdf/2204.13596.pdf">Generative Multi-hop Retrieval</a> (Lee et al. 2022)</li>
            <li><a href="https://arxiv.org/pdf/2210.02068.pdf">Nonparametric Decoding for Generative Retrieval</a> (Lee et al. 2023)</li>
            <li><a href="https://arxiv.org/pdf/2305.16675">Multiview Identifiers Enhanced Generative Retrieval</a> (Li et al. 2023)</li>
          </ul>
          <br />
          <p><b> URLs</b></pp>
            <ul>
              <li><a href="https://arxiv.org/pdf/2208.09257.pdf"><b>Ultron: An ultimate retriever on corpus with a model-based indexer</b></a> (Zhou et al. 2022)</li>
              <li><a href="https://arxiv.org/pdf/2305.11161"><b>TOME: A Two-stage Approach for Model-based Retrieval</b></a> (Ren et al. 2023)</li>
              <li><a href="https://arxiv.org/pdf/2211.09388">Data-efficient Autoregressive Document Retrieval for Fact Verification</a> (Thorne et al. 2022)</li>
             </ul>
          <br />
          <p><b> Pseudo queries</b></pp>
          <ul>
            <li><a href="https://arxiv.org/pdf/2305.15115"><b>Semantic-Enhanced Differentiable Search Index Inspired by Learning Strategies</b></a> (Tang et al. 2023a) </li>
            <li><a href="https://arxiv.org/pdf/2305.16675">Multiview Identifiers Enhanced Generative Retrieval</a>(Li et al. 2023)</li>
            </ul>
            <br />
          <p><b> Important terms</b></pp>
            <ul>
              <li><a href="https://arxiv.org/pdf/2305.13859"><b>Term-Sets Can Be Strong Document Identifiers For Auto-Regressive Search Engines</b></a> (Zhang et al. 2023) </li>
            </ul>
        <br />
        <h5 class="title is-5">3.1.2 Multiple docids represent a document</h5>

        <h4 class="title is-5">3.1.2.1 Single type</h4> 

        <ul>
          <li><a href="https://arxiv.org/pdf/2204.10628"><b>Autoregressive Search Engines: Generating Substrings as Document Identifiers</b></a> (Bevilacqua et al. 2022) </li>
          <li><a href="https://arxiv.org/pdf/2304.14856"><b>A Unified Generative Retriever for Knowledge-Intensive Language Tasks via Prompt Learning</b></a> (Chen et al. 2023b)</li>
          </ul>
          <br />
        <h5 class="title is-5">3.1.2.2 Diverse types</h5>
        <ul>
          <li><a href="https://arxiv.org/pdf/2305.16675"><b>Multiview Identifiers Enhanced Generative Retrieval</b></a> (Li et al. 2023)</li>
          </ul>
          <br />

        <h4 class="title is-5">3.2 Learnable docids</h4>
        <ul>
          <li><a href="https://arxiv.org/pdf/2304.04171.pdf"><b>Learning to Tokenize for Generative Retrieval</b></a> (Sun et al., 2023)</li>
          <li><a href="https://zihanwang314.github.io/pdf/cikm23.pdf"><b>NOVO: Learnable and Interpretable Document Identifiers for Model-Based IR</b></a> (Wang et al., 2023)</li>

        </ul>
          <br />
          <br />
        <h3 class="title is-5">Section 4: Training approaches</h3>
        <h4 class="title is-5">4.1 Stationary scenarios</h4>
        <h5 class="title is-5">4.1.1 Supervised learning</h5>

          <ul>
            <li><a href="https://arxiv.org/pdf/2202.06991.pdf"><b>Transformer Memory as a Differentiable Search Index</b></a> (Tay et al. 2022)</li>
            <li><a href="https://arxiv.org/pdf/2305.15115"><b>Semantic-Enhanced Differentiable Search Index Inspired by Learning Strategies</b></a> (Tang et al. 2023a) </li>
            <li><a href="https://arxiv.org/pdf/2206.10128.pdf"><b>Bridging the Gap between Indexing and Retrieval for Differentiable Search Index with Query Generation</b></a> (Zhuang et al. 2023)</li>
            <li><a href="https://arxiv.org/pdf/2206.02743.pdf">A Neural Corpus Indexer for Document Retrieval</a> (Wang et al. 2022)</li>
            <li><a href="https://arxiv.org/pdf/2305.11841.pdf">How Does Generative Retrieval Scale to Millions of Passages?</a> (Pradeep et al., 2023)</li>

          </ul>
            <br />
        <h5 class="title is-5">4.1.2 Pre-training</h5>

          <ul>
            <li><a href="https://arxiv.org/pdf/2208.07652"><b>CorpusBrain: Pre-train a Generative Retrieval Model for Knowledge-Intensive Language Tasks</b></a> (Chen et al. 2022b)</li>
        </ul>
        <br />
        <h5 class="title is-5">4.1.3 Listwise optimization</h5>

          <ul>
            <li><a href=""><b>Listwise Generative Retrieval Models via a Sequential Learning Process</b></a> (Major revision) (Tang et al. 2023b)</li>
        </ul>

        <br />
        <h4 class="title is-5">4.2 Dynamic scenarios</h4>
        <ul>
          <li><a href="https://arxiv.org/pdf/2212.09744.pdf"><b>DSI++: Updating Transformer Memory with New Documents</b></a> (Mehta et al. 2022)</li>
          <li><a href="https://arxiv.org/pdf/2308.14968.pdf"><b>Continual Learning for Generative Retrieval over Dynamic Corpora</b></a> (Chen et al. 2023a)</li>
          <li><a href="https://arxiv.org/pdf/2307.10323.pdf">IncDSI: Incrementally Updatable Document Retrieval</a> (Kishore et al., 2023)</li>

      </ul>
       
       
        <br />
        <br />
        <h3 class="title is-5">Section 5: Inference strategies</h3>
        <h4 class="title is-5">5.1 A single docid represents a document</h4>
        <!-- <h5 class="title is-5">5.1.1 Constrained beam search with prefix tree</h5> -->

        <p><b> Constrained beam search with prefix tree</b></pp>

          <ul>
            <li><a href="https://arxiv.org/pdf/2010.00904"><b>Autoregressive Entity Retrieval</b></a> (De Cao et al. 2021) </li>
           </ul>
           <br />
        <p><b> Constrained greedy search with inverted index</b></pp>
        <!-- <h5 class="title is-5">5.1.2 Constrained greedy search with inverted index</h5> -->
            <ul>
              <li><a href="https://arxiv.org/pdf/2305.13859"><b>Term-Sets Can Be Strong Document Identifiers For Auto-Regressive Search Engines</b></a> (Zhang et al. 2023) </li>
            </ul>
            <br />
            

        <h4 class="title is-5">5.2 Multiple docids represent a document</h4>
        <p><b>Constrained beam search with FM-index</b></pp>

        <!-- <h5 class="title is-5">5.2.1 Constrained beam search with FM-index</h5> -->
          <ul>
            <li><a href="https://arxiv.org/pdf/2204.10628"><b>Autoregressive Search Engines: Generating Substrings as Document Identifiers</b></a> (Bevilacqua et al. 2022) </li>
          </ul>
          <br />
          <p><b>Aggregation functions</b></pp>
          <!-- <h5 class="title is-5">5.2.2 Aggregation functions</h5> -->
            <ul>
              <li><a href="https://arxiv.org/pdf/2204.10628"><b>Autoregressive Search Engines: Generating Substrings as Document Identifiers</b></a> (Bevilacqua et al. 2022) </li>
              <li><a href="https://arxiv.org/pdf/2305.16675"><b>Multiview Identifiers Enhanced Generative Retrieval</b></a> (Li et al. 2023)</li>
            </ul>
          <br />
          <br />
        <h3 class="title is-5">Section 6: Applications</h3>
        <h4 class="title is-5">6.1 Knowledge-intensive language tasks (KILT)</h4>


        <!-- <p><b> Knowledge-intensive language tasks (KILT)</b></pp> -->
          <ul>
            <li><a href="https://arxiv.org/pdf/2010.00904"><b>Autoregressive Entity Retrieval</b></a> (De Cao et al. 2021) </li>
            <li><a href="https://arxiv.org/pdf/2204.05511"><b>GERE: Generative evidence retrieval for fact verification</b></a> (Chen et al. 2022a)</li>
            <li><a href="https://arxiv.org/pdf/2204.10628">Autoregressive Search Engines: Generating Substrings as Document Identifiers</a> (Bevilacqua et al. 2022) </li>
            <li><a href="https://arxiv.org/pdf/2304.14856">A Unified Generative Retriever for Knowledge-Intensive Language Tasks via Prompt Learning</a> (Chen et al. 2023b)</li>
            <li><a href="https://arxiv.org/pdf/2208.07652">CorpusBrain: Pre-train a Generative Retrieval Model for Knowledge-Intensive Language Tasks</a> (Chen et al. 2022b)</li>
            <li><a href="https://arxiv.org/pdf/2211.09388">Data-efficient Autoregressive Document Retrieval for Fact Verification</a> (Thorne et al. 2022)</li>

          </ul>
            <br />
            <h4 class="title is-5">6.2 Multi-hop retrieval</h4>

            <!-- <p><b> Multi-hop retrieval</b></pp> -->
            <ul>
              <li><a href="https://arxiv.org/pdf/2204.13596.pdf"><b>Generative Multi-hop Retrieval</b></a> (Lee et al. 2022)</li>
            </ul>
            <br />
            <h4 class="title is-5">6.3 Recommendation</h4>

            <!-- <p><b> Recommendation</b></pp> -->
              <ul>
                <li><a href="https://arxiv.org/pdf/2305.05065.pdf"><b>Recommender Systems with Generative Retrieval</b></a> (Rajput et al. 2023)</li>
                <li><a href="https://arxiv.org/pdf/2309.13375.pdf">Generative Retrieval with Semantic Tree-Structured Item Identifiers via Contrastive Learning</a> (Si et al. 2023 )</li>
              </ul>
              <br />
            <h4 class="title is-5">6.4 Code retrieval</h4>

            <!-- <p><b> Code retrieval</b></pp> -->
              <ul>
                <li><a href="https://arxiv.org/pdf/2210.00328.pdf"><b>CodeDSI: Differentiable Code Search</b></a> (Nadeem et al. 2022)</li>
              </ul>
      </div>
    </div>



    <br />
    <!--Code -->
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Available code</h2>
        <ul>
          <li><a href="https://github.com/facebookresearch/GENRE">Autoregressive Entity Retrieval</a> (De Cao et al. 2021) </li>
          <li><a href="https://github.com/ict-bigdatalab/CorpusBrain">CorpusBrain: Pre-train a Generative Retrieval Model for Knowledge-Intensive Language Tasks</a> (Chen et al. 2022b)</li>
          <li><a href="https://github.com/Chriskuei/GERE">GERE: Generative evidence retrieval for fact verification</a> (Chen et al. 2022a)</li>
          <li><a href="https://github.com/ facebookresearch/SEAL">Autoregressive Search Engines: Generating Substrings as Document Identifiers</a> (Bevilacqua et al. 2022) </li>
          <li><a href="https://github.com/liyongqi67/MINDER">Multiview Identifiers Enhanced Generative Retrieval</a> (Li et al. 2023)</li>
          <li><a href="https://github.com/ict-bigdatalab/CLEVER">Continual Learning for Generative Retrieval over Dynamic Corpora</a> (Chen et al. 2023a)</li>
          <li><a href="https://github.com/amy-hyunji/Contextualized-Generative-Retrieval">Nonparametric Decoding for Generative Retrieval</a> (Lee et al. 2023)</li>
          <li><a href="https://github.com/ ArvinZhuang/DSI-QG">Bridging the Gap between Indexing and Retrieval for Differentiable Search Index with Query Generation</a> (Zhuang et al. 2023)</li>
          <li><a href="https://github.com/solidsea98/Neural-Corpus-Indexer-NCI">A Neural Corpus Indexer for Document Retrieval</a> (Wang et al. 2022)</li>
          <li><a href="https://github.com/ict-bigdatalab/UGR">A Unified Generative Retriever for Knowledge-Intensive Language Tasks via Prompt Learning</a> (Chen et al. 2023b)</li>
          <li><a href="https://github.com/VerdureChen/Understanding_DSI">Understanding Differential Search Index for Text Retrieval</a> (Chen et al. 2023c)</li>
          <li><a href="https://github.com/amy-hyunji/Generative-MultihopRetrieval">Generative Multi-hop Retrieval</a> (Lee et al. 2022)</li>
        </ul>

        <br />


        

      
      </div>
    </div>
</section>


<!-- <section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@inproceedings{tang-2023-recent,
      author = {Tang, Yubao and Zhang, Ruqing and Guo, Jiafeng and de Rijke, Maarten},
      booktitle = {SIGIR-AP 2023: 1st International ACM SIGIR Conference on Information Retrieval in the Asia Pacific},
      date-added = {2023-10-07 17:24:48 +0200},
      date-modified = {2023-10-07 17:26:24 +0200},
      month = {November},
      publisher = {ACM},
      title = {Recent Advances in Generative Information Retrieval},
      year = {2023}
}</code></pre>
  </div>
</section> -->


<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
      <a class="icon-link" href="https://github.com/ACL2023-Retrieval-LM" class="external-link" disabled>
        <i class="fab fa-github"></i>
      </a>
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is licensed under a <a rel="license"
                                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
          <p>
            This means you are free to borrow the <a
              href="https://github.com/nerfies/nerfies.github.io">source code</a> of this website,
            we just ask that you link back to this page in the footer.
            Please remember to remove the analytics code included in the header of the website which
            you do not want on your website.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
